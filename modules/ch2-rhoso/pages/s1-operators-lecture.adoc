:time_estimate: 11

= Add-on Operators of Red Hat OpenStack Services on OpenShift

_Estimated reading time: *{time_estimate} minutes*._

Goal::

Describe the OpenStack meta-operator and its child operators.

WARNING: Work In Progress

== The OpenStack Meta-Operator

The Red Hat OpenStack Services on OpenShift product is delivered as a top level add-on operator which manages a set of child add-on operators. Because it manages other add-on operators, it is called a meta operator.

// Is it too soon for this figure? It'll take a while until we actually start explaining them, and for a while we focus on generic concepts from OpenShift

[ Simplified Figure of OpenStack operators and its managed services, without their custom resources ]

Most of these child add-on operators are dedicated to managing indidual OpenStack services, both user-facing (such as Nova and Keystone) and internal infrastrucutre (such as RabbitMQ and OVN). Among the child add-on operators, the External Data Plane Management add-on operator manages RHEL compute nodes of an OpenStack cluster.

NOTE: During this course we qualify references to "Kubernetes operators", which reffer to a kind of software, as "add-on operators" to avoid confusion with the OpenStack Operator and OpenShift Operator personas, which represent human users of OpenStack and OpenShift clusters.

The OpenStack add-on operator is designed to be installed and managed by the Operator Lifecycle Manager (OLM), similar to they way you deploy other Red Hat products and features in Red Hat OpenShift.

Before we can detail the purpose of each of the add-on operators from Red Hat OpenStack Services on OpenShift and their respective custom resource types, we must understand some basic concepts of Kubernetes add-on operators and how Red Hat OpenShift uses them.

== Add-on Operators in Red Hat OpenShift

Red Hat OpenShift was architected, since its 4.0 release, around Kuberbetes add-on operators. Add-on operators manage all aspects if an OpenShift cluster, for example:

* The Kubernetes cluster iself, its nodes, API end points, standard resource controllers, scheduler, and Etcd storage;

* The host operating system on OpenShift cluster nodes: Red Hat CoreOS, wich is a container-optimzed variant of Red Hat Enterprise Linux;

* Integration with external authentication and storage services;

* Varying types of hardware accelerators, such as GPUs and SR-IOV network cards.

* DevOps services, such as CI/CD pipelines and observability signals collection and visualization.

Other Red Hat products which runs on OpenShift are also architected as add-on operators, icluding Red Hat Ansible Platform and Red Hat OpenShift AI.

=== What is a Kubernetes Add-on Operator

A Kubernetes add-on operator is a containerized applications which run on Kubernetes and  provides custom resource types for the Kubenetes API. Instances of these custom API resouces configure the add-on operator itself and the entity (other application, hardware, or external service) that the add-on operator manages.

[ Figure of generic kubernetes add-on operators ]

No programming language runtime constrains the development of add-on operators: they could be programmed in any programming language. Their only requirement is invoking Kubernetes APIs to monitor and change Kubernetes API resource instances. 

Red Hat supports the https://sdk.operatorframework.io/[Operator SDK] for building add-on operators using Go, Java, and Ansible, besides re-packaging helm charts as add-on operators. The Kubernetes community provide additional frameworks and libraries for building Kubernetes add-on operators in a variety of languages, including Python.

You package an add-on operator for distribution as a container image. What really differentiates an add-on operator container image from a regular container image is not the contents of container image itself, but what the application inside it does:

* Add-on operators require access to Kubernetes APIs.

* Add-on operators provides custom resources.

* Add-on operators manage something external to their running container.

An add-on operator is not itself an end-user application workload, but it could manage an end-user application workload.

Add-on operators are also a way of packaging an application for deployment on Kubernetes. The difference between packaging an application as an add-on operator and other ways of packaging applications, such as helm charts or OpenStack Heat templates, are: 

* Add-on operators do more than just install an application: they also configure the application in an oppinionated way, to account for its most common usage scenarios

* Add-on operators provide a higher-level configuration syntax for the application they manage (as custom resources), which should be easier than using the raw configuration files from the original application.

* Add-on operators keep managing the application after its initial deployment, to enable configuration changes, software upgrades, data migration, and other day-2 activities. 

An add-on operator could manage a single instance of an application, meaning there could be only one instance running in the same Kubernetes cluster, or it could manage multiple instances of that application.

=== Installing an Add-on Operator Versus Deploying a Managed Application

Most times, installing an add-on operator does not deploy its managed application. It requires that someone creates a custom resource instance that represents the application, and only in response to that instance creation that the add-on operators starts the application.

It could be an empty custom resource instance, meaning the application runs will defaults from the add-on operator, but it could set very specific configuration values. If you need multiple independent instances of the same application, and the add-on operator supports it, you create multiple custom resource instances, each one with different settings (or not).

Notet that installing an add-on operator in OpenShift is a task for an OpenShift Administrator user, while deploying an application using a custom resouce instance is, most of the times, a task for an OpenShift Operator user.

=== The Operator Lifecycle Manager

Kubernetes add-on operators could be deployed in a Kubernetes clusters the same way as any other application, by creating Kubernetes API resource instances to represent the containers, storage, and networking requirements of the add-on operator. Some vendors provide these API resources as YAML files or helm charts for tweaking and deployment on any Kuberntes cluster.

Red Hat OpenShift provides a better way of deploying Kubernetes add-on operators, by using the Operator Lifecycle Manager (OLM). The OLM adds the concept of operator catalog, which is a container image containing only metadata about add-on operators. Using the metadata from operator catalogs and the metadata from add-on operator images themselves, the Operator Lifecycle Manager can track upgrades of an add-on operator and dependencies between multiple add-on operators.

[ Figure of the OLM, operators, and catalogs ]

Red Hat OpenShift also recognizes additional metadata which enables integration with the OpenShift web console and with OpenShift monitoring metrics and alert, enabling add-on operators to fully integrate with OpenShift cluster management.

The OLM defines a number of Kubernetes API custom resources to manage operator catalogs, available operators for installation, and installed operators in a cluster. And, using its metadata, the OLM can list which API custom resource types belong to which add-on operator.

Red Hat manages a number of operator catalogs, as part of the Red Hat Marketplace, which provide add-on operators from Red Hat and partner products. Red Hat OpenShift also comes preconfigured with community operator catalogs, which offer a number of unsupported open source software.

=== OpenShift Cluster Operators

Not all add-on operators in Red Hat OpenShift are deployed and managed by the Operator Licefycle Manager. A few, selected add-on operators are required by the OpenShift platform itself. They must be installed at OpenShift installation time and upgraded together to newer OpenShift product releases when you upgrade an OpenShift cluster.

[ Figure of cluster vs add-on operators in OpenShift ]

These add-on operators are called cluster operators and managed by the Cluster Version Operator (CVO). In a sense, cluster operators provide the core of Red Hat OpenShift, while add-on operators provide optional features and additional layered products.

The OLM itself is a cluster operator in Red Hat OpenShift, which means all OpenShift clusters are already enabled for installing and managing add-on operators from community and commercial operator catalogs. The CVO manages the deployment and upgrades of an entire Red Hat OpenShift cluster, while the OLM manages the deployment and upgrades of individual add-on operators.

It may happen than an add-on operator release is not compatible with a specific release of Red Hat OpenShift, for a number of reason. Fortunately, the compatibility information is among the metadata of an add-on operator, and both the CVO and OLM will use this metadata: the first, to prevent OpenShift cluster upgrades with would make it incompatible with installed add-on operators; the second, to only install new add-on operators which are compatible with the current OpenShift release of the cluster.

== Custom Resources of the OpenStack Add-on Operator

Back to the OpenStack add-on operator, an OpenStack Administrator is not expected to deal with its child add-on operators, other than for troubleshooting purposes, except for the External Data Plane Management add-on operator.

[ Figure of the OpenStack operator, child operators, and their custom resources, which represent one cluster with possibly multiple node sets ]

Once you install the OpenStack add-on operator in an OpenShift cluster, all child add-on operators are automatically installed by the OLM and the next step is creating API resource instances which represent OpenStack control and data planes. The OpenStack add-on operator manages the first of these API resources itself, and the Extended Data Plane Management add-on operator manages the other three:

// Using printable name instead of their "kind" attributes

//TODO Add somewhere a note about "Kubernetes API resource type" and "resource type"

OpenStack Control Plane::

One instance represents all OpenStack services of an OpenStack cluster. It sets not only which individual services are enabled but also the specific configurations of each service, including their dependencies on Kubernetes storage and networking.

OpenStack Node Set::

Each instance represents a group of compute nodes with similar hardware and purpose, that will receive similar operating system configurations. It lists the individual compute nodes with their host names, IP addresses, and network interfaces, plus a set of Ansible variables for the Data Plane Services which run on those compute nodes.

OpenStack Data Plane Service::

Each instance represents one Ansible playbook which runs against all compute nodes in a Node Set. The External Data Plane Management add-on operator comes with many predefined Data Plane Services, which configure RHEL servers to be OpenStack compute nodes, and an OpenStack Administrator can create more instances to run custom Ansible playbooks to further configure their compute nodes.

OpenStack Data Plane Deployment::

One instance represents the entire dataplane of an OpenStack cluster, by referencing all Node Sets and Data Plane Services in the data plane of a cluster. Each instance actually represents one run of all Ansible playbooks, from each of the Data Plane Services, on all compute nodes from all Node Sets. When an OpenStack Administrator needs to change configurations of compute nodes, they first make changes to their Node Sets and Data Services, and them they create new instances of the Data Plane Deployment custom resource, which triggers a new run of Ansible playbooks.


An instance of the OpenStack Control Plane custom resource can be quite long, even on a minimally configured cluster, because each individual service will include references to its cell database, external load balancers, and other settings which are, most times, replicated between multiple services. Unfortunately, The OpenStack Control Plane custom resource type does not define global default values for most of these common configurations, so you cannot configure them only one.

Instances of the OpenStack Node Set custom resource can also be quite long, because sometimes the value of an Ansible vars is a multi-line Jinja2 template, especially for configuring host network interfaces.

On the other side, an instance of the OpenStack Data Plane Deployment custom resource instance is expected to be short, or at least simpler to read, because it only requires a list of all node sets in an OpenStack cluster. The list of Data Plane Services to run on those node sets is optional, and the External Data Plane Management add-on operator will use a predefined list of services if the list on a Data Plane Deployment instance is empty.

Instances of the Control Plane, Node Set, and Data Plane Deployment resources also provide runtime status information on the healty of OpenStack services and compute nodes.

== Projects of the OpenStack add-on operator

The recommended way of deploying Red Hat OpenStack Services on OpenShift uses two OpenShift projects:

1. The `openstack-operators` project, where you install the OpenStack add-on operator and the OLM installs all its child add-on operators.

2. The `openstack` project, where you create resource instances for the control plane, data plane deployment, and node sets custom resources.

This means that the containers from the OpenStack add-on operator and its child operators run on the first project, and the containers which run componentes of Nova, Neutron, RabbitMQ, and other OpenStack services, run on the second project.
