:time_estimate: 14

= Add-on Operators of Red Hat OpenStack Services on OpenShift

_Estimated reading time: *{time_estimate} minutes*._

Goal::

Describe the OpenStack meta-operator and its child operators.

WARNING: Work In Progress

== The OpenStack Meta-Operator

The Red Hat OpenStack Services on OpenShift product is delivered as a top level add-on operator which manages a set of child add-on operators. Because it manages other add-on operators, it is called a meta operator.

// Antora doesn't display the SVG file but Firefox and Chrome are happy with it
//image::ch2-rhoso-s1-operators-lecture-fig-5.svg[]

image::s1-operators-lecture-fig-1.png[]


Most of these child add-on operators are dedicated to managing indidual OpenStack services, both user-facing (such as Nova and Keystone) and internal infrastrucutre (such as RabbitMQ and OVN). Among the child add-on operators, an OpenStack Administrator usually focus on these two: 

External Data Plane Management add-on operator::

Also called just Data Plane operator, manages RHEL compute nodes of an OpenStack cluster.

Infrastructure add-on operator::

Performs IP Address Management (IPAM) of networks attached to OpenStack clusters and also manages an internal DNSmasq server that supports name resolution for OpenStack compute nodes.

The OpenStack add-on operator is designed to be installed and managed by the Operator Lifecycle Manager (OLM), similar to they way you deploy other Red Hat products and features in Red Hat OpenShift.

NOTE: The Data Plane add-on operator is packaged in the same bundle as the OpenStack add-on operator, so it is not, technically, a child add-on operator. You cannot not see it listed among available operators in the cluster, but you can see its workloads running as an independent operator.

Before we can detail the purpose of each of the add-on operators from Red Hat OpenStack Services on OpenShift and their respective custom resource types, we must understand some basic concepts of Kubernetes add-on operators and how Red Hat OpenShift uses them.

== Add-on Operators in Red Hat OpenShift

Red Hat OpenShift was architected, since its 4.0 release, around Kuberbetes add-on operators. Add-on operators manage all aspects if an OpenShift cluster, for example:

* The Kubernetes cluster iself, its nodes, API end points, standard resource controllers, scheduler, and Etcd storage;

* The host operating system on OpenShift cluster nodes: Red Hat CoreOS, wich is a container-optimzed variant of Red Hat Enterprise Linux;

* Integration with external authentication and storage services;

* Varying types of hardware accelerators, such as GPUs and SR-IOV network cards.

* DevOps services, such as CI/CD pipelines and observability signals collection and visualization.

Other Red Hat products which runs on OpenShift are also architected as add-on operators, icluding Red Hat Ansible Platform and Red Hat OpenShift AI.

=== What is a Kubernetes Add-on Operator

A Kubernetes add-on operator is a containerized application which run on Kubernetes and  provides custom resource types for the Kubenetes API. Instances of these custom API resources configure the add-on operator itself and the entity (other application, hardware, or external service) that the add-on operator manages.

image::s1-operators-lecture-fig-2.png[]

No programming language runtime constrains the development of add-on operators: they could be programmed in any programming language. Their only requirement is invoking Kubernetes APIs to monitor and change Kubernetes API resource instances. 

Red Hat supports the https://sdk.operatorframework.io/[Operator SDK] for building add-on operators using Go, Java, and Ansible, besides re-packaging helm charts as add-on operators. The Kubernetes community provide additional frameworks and libraries for building Kubernetes add-on operators in a variety of languages, including Python.

NOTE: During this course we qualify references to "Kubernetes operators", which reffer to a kind of software, as "add-on operators" to avoid confusion with the OpenStack Operator and OpenShift Operator personas, which represent human users of OpenStack and OpenShift clusters.

You package an add-on operator for distribution as a container image. What really differentiates an add-on operator container image from a regular container image is not the contents of container image itself, but what the application inside it does:

* Add-on operators require access to Kubernetes APIs.

* Add-on operators provides custom resources.

* Add-on operators manage something external to their running container.

An add-on operator is not itself an end-user application workload, but it could manage an end-user application workload.

Add-on operators are also a way of packaging an application for deployment on Kubernetes. The difference between packaging an application as an add-on operator and other ways of packaging applications, such as helm charts or OpenStack Heat templates, are: 

* Add-on operators do more than just install an application: they also configure the application in an oppinionated way, to account for its most common usage scenarios

* Add-on operators provide a higher-level configuration syntax for the application they manage (as custom resources), which should be easier than using the raw configuration files from the original application.

* Add-on operators keep managing the application after its initial deployment, to enable configuration changes, software upgrades, data migration, and other day-2 activities. 

An add-on operator could manage a single instance of an application, meaning there could be only one instance running in the same Kubernetes cluster, or it could manage multiple instances of that application.

=== Installing an Add-on Operator Versus Deploying a Managed Application

Most times, installing an add-on operator does not deploy its managed application. It requires that someone creates a custom resource instance that represents the application, and only in response to that instance creation that the add-on operators starts the application.

It could be an empty custom resource instance, meaning the application runs will defaults from the add-on operator, but it could set very specific configuration values. If you need multiple independent instances of the same application, and the add-on operator supports it, you create multiple custom resource instances, each one with different settings (or not).

Notet that installing an add-on operator in OpenShift is a task for an OpenShift Administrator user, while deploying an application using a custom resouce instance is, most of the times, a task for an OpenShift Operator user.

=== The Operator Lifecycle Manager

Kubernetes add-on operators could be deployed in a Kubernetes clusters the same way as any other application, by creating Kubernetes API resource instances to represent the containers, storage, and networking requirements of the add-on operator. Some vendors provide these API resources as YAML files or helm charts for tweaking and deployment on any Kuberntes cluster.

Red Hat OpenShift provides a better way of deploying Kubernetes add-on operators, by using the Operator Lifecycle Manager (OLM). The OLM adds the concept of operator catalog, which is a container image containing only metadata about add-on operators. Using the metadata from operator catalogs and the metadata from add-on operator images themselves, the Operator Lifecycle Manager can track upgrades of an add-on operator and dependencies between multiple add-on operators.

image::s1-operators-lecture-fig-3.png[]

Red Hat OpenShift also recognizes additional metadata which enables integration with the OpenShift web console and with OpenShift monitoring metrics and alert, enabling add-on operators to fully integrate with OpenShift cluster management.

The OLM defines a number of Kubernetes API custom resources to manage operator catalogs, available operators for installation, and installed operators in a cluster. And, using its metadata, the OLM can list which API custom resource types belong to which add-on operator.

Red Hat manages a number of operator catalogs, as part of the Red Hat Marketplace, which provide add-on operators from Red Hat and partner products. Red Hat OpenShift also comes preconfigured with community operator catalogs, which offer a number of unsupported open source software.

=== OpenShift Cluster Operators

Not all add-on operators in Red Hat OpenShift are deployed and managed by the Operator Licefycle Manager. A few, selected add-on operators are required by the OpenShift platform itself. They must be installed at OpenShift installation time and upgraded together to newer OpenShift product releases when you upgrade an OpenShift cluster.

image::s1-operators-lecture-fig-4.png[]

These add-on operators are called cluster operators and managed by the Cluster Version Operator (CVO). In a sense, cluster operators provide the core of Red Hat OpenShift, while add-on operators provide optional features and additional layered products.

The OLM itself is a cluster operator in Red Hat OpenShift, which means all OpenShift clusters are already enabled for installing and managing add-on operators from community and commercial operator catalogs. The CVO manages the deployment and upgrades of an entire Red Hat OpenShift cluster, while the OLM manages the deployment and upgrades of individual add-on operators.

It may happen than an add-on operator release is not compatible with a specific release of Red Hat OpenShift, for a number of reasons. Fortunately, the compatibility information is among the metadata of an add-on operator, and both the CVO and OLM will use this metadata: the first, to prevent OpenShift cluster upgrades with would make it incompatible with installed add-on operators; the second, to only install new add-on operators which are compatible with the current OpenShift release of the cluster.

== Custom Resources of the OpenStack Add-on Operator

Back to the OpenStack add-on operator, an OpenStack Administrator is not expected to deal with most of its child add-on operators, other than for troubleshooting purposes, except for the Infrastructure and Data Plane add-on operators.

image::s1-operators-lecture-fig-5.png[]

Once you start the installation of the OpenStack add-on operator in an OpenShift cluster, all child add-on operators are automatically installed by the OLM, but this only means that the Red Hat OpenStack Services on OpenShift software is available.

=== Required Resources of an OpenStack Cluster

You actually create and configure an OpenStack cluster by creating and editing instances of four custom resource types. The OpenStack add-on operator manages the first of these custom resources types itself, the Infrastructure add-on operator manages the second, and the Data Plane add-on operator manages the other two.

// Using printable name instead of their "kind" attributes

OpenStack Control Plane::

One instance represents all OpenStack services of an OpenStack cluster. It sets not only which individual services are enabled but also the specific configurations of each service, including their dependencies on Kubernetes storage and networking.

OpenStack Network Configuration::

One instance represents the isolated network topology of an OpenStack cluster. It provides IP subnet address ranges, VLAN IDs, IP routes, and other settings which are consumed by the Data Plane add-on opetator to configure compute nodes.

OpenStack Node Set::

Each instance represents a group of compute nodes with similar hardware and purpose, that will receive similar operating system configurations. It lists the individual compute nodes with their host names, IP addresses, and network interfaces, plus a set of Ansible variables for the Data Plane Services which run on those compute nodes.

OpenStack Data Plane Deployment::

One instance represents the entire dataplane of an OpenStack cluster, by referencing all Node Sets and Data Plane Services in the data plane of a cluster. Each instance actually represents one run of all Ansible playbooks, from each of the Data Plane Services, on all compute nodes from all Node Sets. When an OpenStack Administrator needs to change configurations of compute nodes, they first make changes to their Node Sets and Data Services, and them they create new instances of the Data Plane Deployment custom resource, which triggers a new run of Ansible playbooks.

=== Optional Resources of an OpenStack Cluster

There is a fifth custom resource type, also managed by the Data Plane add-on operator, which enables applying custom configurations to compude nodes, but you can deploy a fully working OpenStack cluster without creating new instances of this fith resource type:

OpenStack Data Plane Service::

Each instance represents one Ansible playbook which runs against all compute nodes in a Node Set. The External Data Plane Management add-on operator comes with many predefined Data Plane Services, which configure RHEL servers to be OpenStack compute nodes, and an OpenStack Administrator can create more instances to run custom Ansible playbooks to further configure their compute nodes.

There are too many additional custom resource types defined by the child add-on operators of the OpenStack add-on opetator to list here, and most of the time an OpenStack Administrator will have no need to deal with them. 

=== Cardinality of OpenStack Custom Resources

One OpenStack cluster can have only one instance of the Control Plane resource instance and one instance of the Network Configuration custom resource, but it could include many instances of the Node Set, Data Plane Deployment, and Data Plane Service custom resources.

An instance of the Control Plane custom resource can be quite long, even on a minimally configured cluster, because each individual service will include references to its cell database, external load balancers, and other settings which are, most times, similar between multiple services.

Instances of the Node Set custom resource can also be quite long, because the value of Ansible variables can be multi-line Jinja2 templates.

On the other side, instances of the Network Configuration custom resource are expected to be relatively short, because they only require a list of all external networks connected to compute nodes of an OpenStack cluster.

Similarly, instances of the Data Plane Deployment custom resource are also expected to be short, or at least simpler to read, because they only requires a list of node sets in an OpenStack cluster. The list of Data Plane Services to run on those node sets is optional, and the Data Plane add-on operator will use a predefined list of services if the list on a Data Plane Deployment instance is empty.

=== Health Status of the OpenStack clusters

Instances of the Control Plane, Node Set, and Data Plane Deployment resources also provide detailed runtime status information on the healty of OpenStack services and compute nodes in the form of resource conditions. The main way of assessing the healhy of an OpenStack cluster is by querying the status attribute of those resource instances, for example:

* The status conditions of a Control Plane resource specifies the status of each of the enabled user-facing and internal infrastructure services of OpenStack.

* The status conditions of a Node Set resource instance specifies the status of each of its data plane services, meaning the respective Ansible playbook executed to successful completion or not.

=== Projects of OpenStack clusters

The recommended way of deploying Red Hat OpenStack Services on OpenShift uses two OpenShift projects or Kubernetes namespaces:

1. The `openstack-operators` project, where you install the OpenStack add-on operator and the OLM installs all its child add-on operators. 

2. The `openstack` project, where you create resource instances for the control plane, data plane deployment, and other custom resources which describe an OpenStack cluster.

This means that the containers from the OpenStack add-on operator and its child operators themselves run on the first project, while the containers which run componentes of Nova, Neutron, RabbitMQ, and other OpenStack services run on the second project.

