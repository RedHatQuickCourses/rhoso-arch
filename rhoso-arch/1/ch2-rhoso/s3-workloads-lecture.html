<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>OpenStack Services as OpenShift Workloads :: Red Hat OpenStack Services on OpenShift Architecture</title>
    <link rel="prev" href="s2-operators-quiz-answers.html">
    <link rel="next" href="s4-workloads-quiz.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Red Hat OpenStack Services on OpenShift Architecture</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/rhoso-arch/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="rhoso-arch" data-version="1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Red Hat OpenStack Services on OpenShift Architecture</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../ch1-architecture/index.html">Architecture of Red Hat OpenStack Services on OpenShift</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../ch1-architecture/s1-components-lecture.html">Components of Red Hat OpenStack on OpenShift</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../ch1-architecture/s2-components-quiz.html">Quiz: Components of Red Hat OpenStack on OpenShift</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../ch1-architecture/s2-components-quiz-answers.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../ch1-architecture/s3-tasks-lecture.html">OpenStack Administrator Tasks and Tools</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../ch1-architecture/s4-tasks-quiz.html">Quiz: OpenStack Administrator Tasks and Tools</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../ch1-architecture/s4-tasks-quiz-answers.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../ch1-architecture/s5-openshift-demo.html">Demo: OpenShift Web Console and Client</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../ch1-architecture/s6-services-lecture.html">OpenStack User-Facing Services and Internal Services</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../ch1-architecture/s7-services-quiz.html">Quiz: OpenStack Internal Services on OpenShift</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../ch1-architecture/s7-services-quiz-answers.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../ch1-architecture/s8-summary.html">Summary</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">The OpenStack Operator by Red Hat</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="s1-operators-lecture.html">Add-on Operators of Red Hat OpenStack Services on OpenShift</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="s2-operators-quiz.html">Quiz: Add-on Operators of Red Hat OpenStack Services on OpenShift</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="s2-operators-quiz-answers.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="s3-workloads-lecture.html">OpenStack Services as OpenShift Workloads</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="s4-workloads-quiz.html">Quiz: OpenStack Services as OpenShift Workloads</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="s4-workloads-quiz-answers.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="s5-workloads-demo.html">Demo: OpenStack Pods and Workloads</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="s6-summary.html">Summary</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../ch3-connectivity/index.html">OpenShift Networking and Storage with OpenStack</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../ch3-connectivity/s1-networking-lecture.html">Kubernetes Networking for OpenStack Services</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../ch3-connectivity/s2-networking-quiz.html">Quiz: Kubernetes Networking for OpenStack Services</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../ch3-connectivity/s2-networking-quiz-answers.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Red Hat OpenStack Services on OpenShift Architecture</span>
    <span class="version">1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Red Hat OpenStack Services on OpenShift Architecture</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Red Hat OpenStack Services on OpenShift Architecture</a></li>
    <li><a href="index.html">The OpenStack Operator by Red Hat</a></li>
    <li><a href="s3-workloads-lecture.html">OpenStack Services as OpenShift Workloads</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">OpenStack Services as OpenShift Workloads</h1>
<div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p><em>Estimated reading time: <strong>18 minutes</strong>.</em></p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Goal</dt>
<dd>
<p>Describe how OpenStack services run as Kubernetes workloads and pods.</p>
</dd>
</dl>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Pending Review
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_openstack_services_as_containers"><a class="anchor" href="#_openstack_services_as_containers"></a>OpenStack Services as Containers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Packaging and running OpenStack services as containers is not a new idea from Red Hat OpenStack Services on OpenShift. The OpenStack community was already experimenting with different ways of doing that, with and without Kubernetes. In fact, previous incarnations of Red Hat OpenStack Platform run OpenStack services as podman containers and manage these containers using Linux systemd and Ansible.</p>
</div>
<div class="paragraph">
<p>Despite all advantages of just packaging and running individual applications as containers, complex service-oriented applications benefit from an orchestration layer and Kubernetes is established as the preferred container ochestration tool. Red Hat OpenShift, as an application platform based on Kubernetes, benefits an OpenStack control plane as a whole and also individual services of OpenStack with their many components, such as Nova.</p>
</div>
<div class="paragraph">
<p>OpenStack itself has a multi-layered architecture: from its user-facing and infrastructure services, passing trhough the individual components of each service, down to the operating system processes of each component. Red Hat OpenStack Services on OpenShift maps this multi-layered architecture to Kubernetes add-on operators, Kubernetes workloads, Kubernetes pods, and containers.</p>
</div>
<div class="paragraph">
<p>As a Linux System Administrator, an OpenStack Administrator is expected to have basic knowledge of <a href="https://www.redhat.com/en/topics/containers/whats-a-linux-container">Linux Containers</a>, or simply containers, and how they differ from Virtual Machines (VMs). If you are new to containers, we suggest that you pause to review the relevant sections of <a href="https://www.redhat.com/en/services/training/rh134-red-hat-system-administration-ii">RH134</a> and <a href="https://www.redhat.com/en/services/training/do080-deploying-containerized-applications-technical-overview">DO080</a>.</p>
</div>
<div class="paragraph">
<p>This section continues the explanation the Kubernetes concepts related to managing containerized applications with a top-down approach: the previous sections presented Kubernets add-on operators, this section presents Kubernetes workloads, pods, and containers.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kubernetes_application_resources"><a class="anchor" href="#_kubernetes_application_resources"></a>Kubernetes Application Resources</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Kubernetes represents containerized applications using many API resource types, and the main one is the <strong>Pod</strong>, which represents a group of containers sharing Linux kernel namespaces. Pods are managed by a workload controller, such as a Deployment or a Job. Pods need configuration data, which is represented by Secrets and Configuration Maps. Connectivity between Pods, or from outside of a Kubernetes cluster and its Pods, comes from Services and Ingress or from OpenShift Routes. Finally, persistent storage mounted by Pods is represented by Persistent Volume Claims (PVCs).</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/s3-workloads-lecture-fig-1.png" alt="s3 workloads lecture fig 1">
</div>
</div>
<div class="paragraph">
<p>Kubernetes Operator users can only create and manage resources inside the projects they have acess to, but they also have read-only access to selected resources outside their projects, such as Storage Classes and Persistent Volumes.</p>
</div>
<div class="paragraph">
<p>The next chapter will focus on the API resources related to storage and networking, including OpenShift custom resources not shown in the figure. This section focus on the API resources required to manage containers and their configuration data.</p>
</div>
<div class="sect2">
<h3 id="_kubernetes_namespaces_and_openshift_projects"><a class="anchor" href="#_kubernetes_namespaces_and_openshift_projects"></a>Kubernetes Namespaces and OpenShift Projects</h3>
<div class="paragraph">
<p>Kubernetes organanizes API resource instances in Namespaces, and users are granted access to projects using Role-Based Access Control (RBAC). Kubernetes Operators are granted the <code>edit</code> role in a project, meaning they can create and manage resource instances of a restricted set of resource types, which allows them to deploy and manage applications. Kubernetes Administrators get the <code>admin</code> role, which alows them to create and manage instaces or a larger set of resource types, including Role Binding resources and Rresource Quotas.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/s3-workloads-lecture-fig-2.png" alt="s3 workloads lecture fig 2">
</div>
</div>
<div class="paragraph">
<p>Most Kubernetes API resource types are namespaced resources, meaning they must exist inside a Kubernetes Namespace, and their names would not collide with resources of the same type in different Namespaces. A few API resource types are non-namespaced, meaning they exist outside any Namespace. Kubernetes Cluster Administrators get the <code>cluster-admin</code> role to manage those non-namespaced resources, and also instances of all resource type in all namespaces.</p>
</div>
<div class="paragraph">
<p>A Kubernetes Operators may get <code>admin</code> in some namespaces but not in others, meaning they are namespace administrators instead of cluster administrators. An OpenStack Administrator may either be an administrator of the two projects of the OpenStack add-on operator or be just ab Operator of those projects, getting the <code>edit</code> role.</p>
</div>
<div class="paragraph">
<p>With standard Kubernetes, only Cluster Administrators can create namespaces, which is too restrictive for application developers: they must either ask an administrator to create and configure projects for them, or pile too many unrelated applications in the namespaces they already have access to.</p>
</div>
<div class="paragraph">
<p>Red Hat OpenShift extends Kubernetes with Projects, which are, for most practical purposes, the same as Kubernetes namespaces. Any user of OpenShift, of a selected group of users granded the <code>self-service</code> role, can create new Projects and these become Kuberentes namespaces.</p>
</div>
<div class="paragraph">
<p>Those self-service namespaces are created with a default set of API resources, which is predefined by Red Hat to grant the project creator <code>admin</code> on their new projects, and can be further customized by cluster administrators to include more resource instances or give fewer privileges to the projet creator.</p>
</div>
</div>
<div class="sect2">
<h3 id="_kubernetes_workloads"><a class="anchor" href="#_kubernetes_workloads"></a>Kubernetes Workloads</h3>
<div class="paragraph">
<p>The concept of application varies with programming language, architecture style, and other factors, so Kubernetes offer a number of resource types to represent applications. These same resource types could represent only a piece of a larger application, such as a component of an OpenStack service. These resource types are part of the Kubernetes Workloads API.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/s3-workloads-lecture-fig-3.png" alt="s3 workloads lecture fig 3">
</div>
</div>
<div class="paragraph">
<p>Kubernetes workload resources types, also known as Kubernetes workload controllers, represent the scalability and availability requirements of an application or component, for example: a network server application, such an OpenStack API endpoint, must be running continously. If, by any reason, that API edpoint stops running, a workload controller will start another instance, so users can always invoke those APIs.</p>
</div>
<div class="paragraph">
<p>Not all applications must run continously, and sometimes you must run many copies of the same application, no matter in which node of a Kubernetes cluster. Other times, it does matter which node, and you may need exactly one instance per cluster node, but not more nor less. The different types of Kubernetes workload controllers deal with those varying application requirements:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Replica Set</dt>
<dd>
<p>Represents a stateless application which runs multiple Pods that are copies, or replicas, of each other, in the sense that any user request could be processed by any of the replicas and responding to user requests do not depend on any state stored on the memory of a specific Pod. Replica pods do not keep their identity, if recreated, so they cannot restore any data specific to the pod from an external store such as a cache service. It is the workload controller that provide horizontal scalability for applications, but it is rarelly used directly: Kubernetes Operators typically create, Deployments which in turn create Replica Sets.</p>
</dd>
<dt class="hdlist1">Deployment</dt>
<dd>
<p>Represents a stateless application and manages its upgrade process, by either rolling out new Pods, while deleting old Pods, little by little, or by replacing all old pods at once with new pods. If the application design supports it, progressive rolling out new Pods is better than replacing all at one, because it avoids downtime as perceived by end users. Old and new pods are managed as two Replica Sets. Deployments are the most common workload controllers with cloud-native applications on Kubernetes.</p>
</dd>
<dt class="hdlist1">Job</dt>
<dd>
<p>Represents an application which runs once through completion. A Job can retry a number of times, and whatever the end result, and a Job resource instance keeps the status of completion, either successful or not (after attempting all retries). You may see many jobs that fire at OpenStack add-on operator installation, or at significant events such as adding new compute nodes to an OpenStack cluster.</p>
</dd>
<dt class="hdlist1">Cron Job</dt>
<dd>
<p>Represents an application which runs with a recurrent schedule. Each indivdual execution of the schedule is a Job resource. Cron Jobs fits nicely periodic tasks, such as purging records marked for deletion from a database.</p>
</dd>
<dt class="hdlist1">Stateful Set</dt>
<dd>
<p>Represents an application which may require multiple Pods, similar to a Replica Set, but that are not replicas of each other, in the sense that each Pod of the set performs different tasks and may depend on state on the Pod&#8217;s own memory to continue executing those tasks. Pods from a Stateful Set must somehow syncronize state between themselves and they retain their identity, so a replacement Pod can resume the work of a specific previous Pod, and they must be designed to retrieve their state from other Pods of their set or from an external store such as a database. Primary/secondary databases, such as relational databases with one read-write and multiple read-only replicas, and noSQL databases with multiple shards, are examples of workloads which fit a stateful set.</p>
</dd>
<dt class="hdlist1">Daemon Set</dt>
<dd>
<p>Represents an application which must run in all cluster node or a subset of those nodes. It ensures there is always one and only one Pod of that workload running in each and all of the elligible Kubernetes cluster nodes. Controllers for hardware acellerator cards are typical examples of Daemon Sets.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>It&#8217;s common with Kubernetes that multiple API resource types work in layers, or as different abstraction levels, to manage the one application or a piece of a larger application. For example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A Deployment instance manages one or two Replica Set instances, which in turn manage one or more Pod instances each.</p>
</li>
<li>
<p>A Cron Job instance which creates new Job instances, everytime its schedule requires, and each Job instance manages one Pod instance, or possibly multiple Pod instances, if there were retries.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>That design pattern of resource instances which manage other resource instances is extended to Kubernetes add-on operators, where each add-on operator instance may manage multiple workload controllers, and a custom resource from an add-on operator may manage multiple application workloads.</p>
</div>
</div>
<div class="sect2">
<h3 id="_stateless_and_stateful_componentes_of_openstack_control_planes"><a class="anchor" href="#_stateless_and_stateful_componentes_of_openstack_control_planes"></a>Stateless and Stateful Componentes of OpenStack Control Planes</h3>
<div class="paragraph">
<p>OpenStack services use an stateless API design but that does not mean all OpenStack services and their components are stateless. Many factors come in the implementation of individual components which may require internal state and syncronization between instances of that component or with other components of the same service.</p>
</div>
<div class="paragraph">
<p>Locality is an important factor that affects performance and reliability and few OpenStack services have a pure stateless design, despite all of them delegating persistence of their API resources to relational databases.</p>
</div>
<div class="paragraph">
<p>For example, the API component of an OpenStack service may also manage data storaed in an external storage backend, which is acessed by workloads running as VMs on compute nodes. Or that API component may use caching to improve its performance.</p>
</div>
<div class="paragraph">
<p>Many Kubernetes Operators, used to the <a href="https://12factor.net/">12-factor</a> style of cloud-native application design, would expect that OpenStack services run mostly as Kubernetes Deploymetns, and will be surprised that so many services run entirely from Stateful Sets. Most times, the determining factor for the Red Hat OpenStack Services on OpenShift enginnering choice was the need to preserve the network identity of individual pods of a component, which you cannot do with Kubernetes Deployments.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kubernetes_pods_and_containers"><a class="anchor" href="#_kubernetes_pods_and_containers"></a>Kubernetes Pods and Containers</h2>
<div class="sectionbody">
<div class="paragraph">
<p>All isolation between containers come from starting them inside different Linux Kernel namespaces. Unlike virtual machines, which are always completely isolated from their host operating system, a container may be only partially isolated, depending on its namespaces. Kubernetes offers control of which namespaces are isolated or not for groups of containers, called Pods, and OpenShift uses that to enable platform-level components which provide advanced networking, storage, and security features.</p>
</div>
<div class="sect2">
<h3 id="_containers_and_linux_kernel_namespaces_in_kubernetes"><a class="anchor" href="#_containers_and_linux_kernel_namespaces_in_kubernetes"></a>Containers and Linux Kernel Namespaces in Kubernetes</h3>
<div class="paragraph">
<p>There are many types of Kernel namespaces: uid namespaces, mount namespaces, process namespaces, network namespaces, and so on. Containers do not require all types of namespaces, and containers may belong to different namespaces which interscet with other containers. Containers may run on host namespaces, which enables them to perform privileged operations on a node of an OpenStack or OpenShift cluster.</p>
</div>
<div class="paragraph">
<p>For example, a container may run on its isolated process and mount namespace, but run on the network namespace of its host, and this way manage host networking. Like NMState and MetalLB add-on operators to.</p>
</div>
<div class="paragraph">
<p>Another example, a container may run on its isolated process and network namespaces, but not on the mount namespaces, and thus control storage devices and mount points of its host. Like any CSI driver such as the LVMS add-on operator or OpenShift Data Foundation do.</p>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
Kubernetes currently does not take advantage of all types of Kernel namespaces available in Linux, and some of these namespaces are very tricky to use together, such as the uid or user namespace versus the mount namespace. The tricky part comes from managing file and group ownership of files, thus current releases of Kubernetes run all containers without user namespace isolation: a container running in Kubernetes as the Linux root user has all root user privileges on its host, unless constrained by other Linux features such as SELinux and Kernel capabilities.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="_kubernetes_pods"><a class="anchor" href="#_kubernetes_pods"></a>Kubernetes Pods</h3>
<div class="paragraph">
<p>A Pod in Kubernetes is a group of containers which share some Kernel namespaces, especially the network namespace, and run with other dedicated kernel namespaces, such as the process and mount namespaces. Once kubernetes schedules a Pod to a cluster node, all containers from the Pod run in the same node. Else, they would not be able to share Kernel namespaces.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/s3-workloads-lecture-fig-4.png" alt="s3 workloads lecture fig 4">
</div>
</div>
<div class="paragraph">
<p>Some containers from a Pod may run sequentially, for example the init containers, which perform whatever initialization its required before starting the main application container, and multiple initialization tasks may be required in strict order.</p>
</div>
<div class="paragraph">
<p>Other containers from a pod may run in parallel, for example the side-car containers, which complements the main application container with support tasks such as network proxying and access control.</p>
</div>
<div class="paragraph">
<p>It is common having Pods which run a single container, but the possibility of running multiple containers on the same Pod enables reusing container images as building blocks or larger application components.</p>
</div>
<div class="paragraph">
<p>It is a recommended practice to avoid joining large applicaiton components in the same Pod, for example: running a web application and its database on the same Pod is considered an anti-pattern.</p>
</div>
<div class="paragraph">
<p>It may seem intuitive running a web application and its database on the same Pod, especially if that application used to connect to its database on localhost, but it also impacts Kubernetes ability to manage the performance and high availability of those components, because they must run together, in the same Kubernetes cluster node, and be scaled together.</p>
</div>
<div class="paragraph">
<p>For that example of an application and its database, it would be better having the ability to spread the web application and its database on different nodes, and being able to run scale Pods of the web application independently of their database Pods.</p>
</div>
</div>
<div class="sect2">
<h3 id="_references_to_pods_and_their_workload_controllers"><a class="anchor" href="#_references_to_pods_and_their_workload_controllers"></a>References to Pods and Their Workload Controllers</h3>
<div class="paragraph">
<p>It is common to see Pod resource instances named with a random hash as a suffix of their names: this is usually a sign that the Pod instance was created by a workload controller, such as a Replica Set or Job, and that resource controller must generate unique names for each of its Pods.</p>
</div>
<div class="paragraph">
<p>A resource controller may leave old Pods around, so a Kubernetes Operator may inspect its termination state and configuration settings, or may purge (delete) them as soon as they are not needed anymore. Each resource controller will have different policies for keeping or purging their old pods.</p>
</div>
<div class="paragraph">
<p>Note that pods from a steful set do not get a random suffix. They require a consistent identity, and new pods take over the name of the original pods they replace.</p>
</div>
<div class="paragraph">
<p>Most workload controllers do not refer to Pods directly by their names. They refer to pods by their <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">labels</a>. Any Kubernetes resource instance can include multiple labels, and Kubernetes Operators can search for those instances by label.</p>
</div>
<div class="paragraph">
<p>This way, any workload controller can manage multiple pods, such as replicas in a Replica Set or retries of a Job, without storing their unique names. And, from the labels, you can infer which workload controller instance manages (or owns) a Pod instance.</p>
</div>
<div class="paragraph">
<p>Other Kubernetes API resource types use labels in a similar way, for example:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Kubernetes Services, which are network load balancers, refer to Pods by label instead of by IP address or by name.</p>
</li>
<li>
<p>Kubernetes Network Policies are network firewalls that control network traffic between Pods in the same or different Namespaces by labels on the Pods and Namespaces instead of by IP address range.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Whenever a Kubernetes API resource instance manages another resource instance, it is expected that it sets an <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/owners-dependents/">owner reference</a> in the managed instance. For example, a Replica Set instance sets itself as the owner of all Pod instances it creates, and a Deployment instance sets itself as the owner of all Replica Sets it creates.</p>
</div>
<div class="paragraph">
<p>Well-designed add-on operators will set owner references all the way, so you could track any Pod and other resources to the add-on operator which ultimately manages them.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_kubernetes_application_configuration_resources"><a class="anchor" href="#_kubernetes_application_configuration_resources"></a>Kubernetes Application Configuration Resources</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Workload controllers and Pods are not sufficient to describe typical cloud-native and other kinds of applications or components. At the beginning of this section we mentioned other application resources from Kubernetes, such as Services, Configuration Maps, and Persistent Volume Claims. Add-on operators could add more application resource types or add more functionality over standard Kubernetes resource types.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/s3-workloads-lecture-fig-5.png" alt="s3 workloads lecture fig 5">
</div>
</div>
<div class="paragraph">
<p>The next chapter will present Kubernetes standard API resources and OpenShift custom resources which deal with persistent storage and networking, but here we introduce two resource types which provide applications with their configuration settings:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Configuration Maps</dt>
<dd>
<p>A configuration map (or <code>ConfigMap</code>) provides key/value pairs. Pods refer to those keys to initialize operating system environment variables on containers, or to initialize configuration files which are mounted on their containers.</p>
</dd>
<dt class="hdlist1">Secrets</dt>
<dd>
<p>Secrets are similar to configuration maps, except that their values can be binary data, and they are never stored on disk on compute nodes. These differences make Secrets a bit better suited for sensitive data such as passwords and digital certificates.</p>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Red Hat OpenShift enforces encryption of data from Secrets, as they are on transit from an OpenShift control plane to its compute nodes, and can be configured for encryption at rest, for secret data stored in an OpenShift control plane. Add-on operators, such as the <a href="https://www.redhat.com/en/blog/how-to-setup-external-secrets-operator-eso-as-a-service">External Secrets</a> add-on operator and the <a href="https://www.redhat.com/en/blog/introducing-the-secret-store-csi-driver-in-openshift">Secrets Store CSI driver</a> add-on operator can be enabled improve the security of secrets at rest and on transit.</p>
</div>
<div class="paragraph">
<p>Most application workloads, and OpenStack services are not exception, expect configuration data stored in Kubernetes configuration maps and secrets resource instances. Some of them are mandatory when deploying Red Hat OpenStack Services on OpenShift, and you will see them in the <code>openstack</code> namespace; others are generated at runtime by the OpenStack add-on operators and its child operators, which produce complete and raw configuration files, as expected by OpenStack services.</p>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="s2-operators-quiz-answers.html">Answers to the Quiz</a></span>
  <span class="next"><a href="s4-workloads-quiz.html">Quiz: OpenStack Services as OpenShift Workloads</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
